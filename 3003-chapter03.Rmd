# 元分析 {#meta}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # Wickham的数据整理的整套工具
pdf.options(height=10/2.54, width=10/2.54, family="GB1") # 注意：此设置要放在最后
```

## 元分析中的常见概念及原理 {#meta-concept}

**1. 同质性检验**

同质性检验回答的是不同的研究样本是否来自于同一个总体。如果所收集的文献中的研究样本来自于同一个总体，那么在接下来的分析中应当选用固定效应模型；如果不是来自于同一个总体，后续分析中应当选用随机效应模型。

从以上的论述中可以看出：固定效应模型(Fixed Effect Model)假设元分析中所包含的研究样本都来自于同一个样本总体。因为这个总体的平均效应值是固定的，所以来自这个总体的不同研究样本所得出的效应值在理论上应该也是同质(Homogeneous)的；随机效应模型(Random Effect Model)假设元分析中的研究样本是来自于不同的总体，由于不同总体存在不同的效应值，那么不同研究样本的效应值在理论上应该是异质的(heterogeneous)。

固定效应模型认为误差主要是由于同一总体的抽样误差所造成的；而随机效应模型则认为误差不仅存在于抽样误差，同时也包括不同总体间的效应值的差异。

**1.1 总体的相关系数($\rho$)与研究样本的抽样分布方差($S_{e}^{2}$)的关系** 

$$
S_{e}^{2}={{(1-\rho^2)^2}\over{N-1}}
$$

$S_{e}^{2}$是当我们从相关系数是$\rho$的总体中抽出样本数为$N$的样本时，不同样本的相关系数($r$)的概率分布的方差。



从上式可知，总体相关系数越大($r$)，样本的相关系数离总体的相关系数的差异($S_{e}^{2}$)就越小；样本量($N$)越大，样本的相关系数离总体的相关系数的差异($S_{e}^{2}$)就越小。

正是因为上述的原因，由于不同研究的样本量存在差异，虽然可能它们是来自于同一个总体，但我们观察到它们各自的样本相关系数都会不一样。

**1.2 同质还是异质？(是否存在调节变量)**

我们可以建立如下公式：

$$
S_{\rho}^{2}=S_{r}^{2}-S_{e}^{2}
$$

即总体相关系数的方差=观察到相关系数的方差-抽样误差引起的方差。

$S_{r}^{2}$是我们从不同的样本中观察到的不同的相关系数所形成的方差，为观察方差(observed variance)。

$S_{\rho}^{2}$是假设不同的样本是从不同的总体中抽出来的，不同的总体有不同的相关系数。所以，这些不同的总体相关系数就形成了方差，称之为真实方差(true variance)，其代表了不同总体中相关系数的真实差异。

而$S_{e}^{2}$代表假的方差(artifactual variance)，是由于抽样而产生的方差。

如果$S_{\rho}^{2}\leqslant0$，就代表总体中相关系数没有方差，即样本背后只有一个总体，也就是只有一个总体相关系数。在这种情况下，不同样本相关系数的差异，就完全是抽样误差所引起的。如果$S_{\rho}^{2}>0$,大致可以判断样本背后应该有不同的总体，不同的总体有不同的相关系数。

如果抽样方差能够解释观察方差的75%(${{S_{e}^{2}}\over{S_{r}^{2}}}\geqslant$ 75%)，就可以判断样本都是从同一个总体抽出来的，没有必要寻找可能的调节变量。如果${{S_{e}^{2}}\over{S_{r}^{2}}}$ < 75%，就有必要寻找是否有调节变量的存在。

**1.2.1 $Q$统计量**

除去75%法则，$Q$统计量也可作为判断研究间是否存在异质性的依据，公式为： 

$$
Q=\sum_{i=1}^{k}(n_{i}-3)(z_{i}-z_{+})^{2}
$$

其中，$z_{i}$是不同研究样本的相关系数，是用$FisherZ$转换成的$Z$值。$Z$值的计算公式为：

$$
FisherZ={1\over2}ln{{(1+r)}\over{(1-r)}}
$$

$z_{+}$是整个元分析的加权平均相关系数，是用$FisherZ$转换成的$Z$值。

$n_{i}$是不同研究的样本量。

$Q$统计量服从$\chi^{2}$分布。我们的零假设是总体中只有一个相关系数。如果$Q$统计量不显著，就代表在总体中只有一个相关系数，没有必要进一步寻找调节变量了。

**1.2.2 $H$统计量**

进一步地,$H$检验是$Q$统计量的校正值。计算公式为： 

$$
H=\sqrt{{Q}\over{k-1}}
$$

其中，$k$是纳入研究的数量，如果${Q}\over{k-1}$<1，则视$H$=1。

$H$=1表示研究间无异质性;$H$介于1.2和1.5之间，如果$H$值的95%CI包含1，则在0.05检验水平下无法确定是否存在异质性，若不包含1则认为存在异质性;$H$>1.5则表示研究间存在异质性。

**1.2.3 $I^{2}$统计量**

$I^{2}$描述了研究间变异占总变异的百分比，计算公式为： 

$$
\left\{ \begin{aligned} 
        I^{2} = {{{Q-df}\over{Q}},Q>df} \\
        I^{2} = 0,{Q}\leqslant{df}
\end{aligned} \right.
$$

其中，$df$是$Q$统计量的自由度。当$I^{2}$=0%时，研究间无异质性；25%为轻度异质性；50%为中度异质性；75%为高度异质性。

**2. 发表偏倚检验**

**2.1 漏斗图**

漏斗图(funnel plot)，是使用效应值和样本量作为坐标系，将各个研究绘制在坐标系里的散点图。对于样本量越大的研究样本来说，其效应值估计也就越准确，误差也越小。呈现在漏斗图中，样本量大的研究样本会集中在图的上方、平均效应值的周围；而样本量小的研究样本则会散落在漏斗图的底部，距离平均效应值较远。

具体来说，如果图形呈现一个倒着的漏斗形状，则表明发表偏差不太可能存在；如果漏斗图不对称，有缺角，则表明发表偏差可能存在。

漏斗图是一种主观的定性判断有无发表偏倚的方法，不同的人对漏斗图对称性可能会做出不同的判断。客观的统计检验方法主要有Begg秩相关检验和Egger's回归系数检验。

**2.2 剪补法**

剪补法(Trim and Fill)是将不对称的漏斗图中的研究样本进行删减，使其变成对称的漏斗，并对校正后的样本重新估计。基本过程主要包括：剪掉引起漏斗图中不对成的小样本研究；用修剪后的对称部分估计漏斗图的中心值；然后沿中心两侧添补被剪切的以及相应的估计缺失研究。剪补法既可以估计缺失研究的数目，也可以将缺失研究纳入重新进行Meta分析。

剪补法是基于发表偏倚会造成漏斗图不对称这一研究假设，采用迭代方法估计缺失研究的数量。其意义不是估计缺失研究的具体数目，而在于判断结果的稳健性。在添补一部分研究后，重新进行Meta分析。如果合并效应量估计值与剪补之前的变化不明显，说明发表偏倚不是很严重，结果比较稳健。

2.3 失安全系数

因为结果不显著的研究成果是很难发表的。在解释元分析的结果时, 应该充分考虑这种"发表偏倚"或"抽屉文件效应"(file-drawer effect, 指结果不显著的研究成果最终只能锁在抽屉里)。

失安全系数(fail-safe N, Nfs)，估计还需要存在多少未发表的研究才能将现有的研究结果从显著变得不显著。Nfs越大, 说明元分析的结果越稳定, 结论被推翻的可能性就越小。

**2.4 森林图和累积森林图**

森林图(forest plot)，让研究者"既见树木又见森林"。它有助于研究者正确解释分析结果，并能发现纳入研究的一些异常情况(如某个极端值)，可以视森林图为发表偏倚的初步视觉印象。

累积Meta分析是把纳入的研究作为一个连续的整体，将各个纳入的研究按一定的次序(如研究发表的时间、样本量大小、研究质量评分)，依次地加在一个研究上，进行多次Meta分析。每当有新的研究发表后，就可以进行一次Meta分析。累积Meta分析可以反映研究结果的动态变化趋势，有助于尽早发现有统计学意义的干预措施，同时也能被应用于评估发表偏倚或小样本研究对效应量估计产生的潜在影响。累积Meta分析作出来的森林图即是累积森林图。

**3. 敏感性分析**

敏感性分析(Sensitivity Analysis)，是在一定条件下检验所获结果稳健性的方法，改变某些影响合并结果的重要性(如纳入标准、研究质量的高低、不同统计方法和不同效应量等)，重新进行Meta分析之后，与改变条件之前的Meta分析进行比较，观察前后是否发生变化。如果前后结果没有本质上改变(无改变或改变不大)，说明Meta分析结果较为可信；反之，则不太可信[@zhangyi2009:RNG]。

剪补法和失安全系数法其实就是两种常见的敏感性分析方法。

**4. 主效应检验**

**4.1 如何计算效应值**

在固定效应模型中，首先通过$FisherZ$转换将每一个研究的相关系数$r$转换成$Z$值，转换后的$Z$值可以通过下面的公式计算加权平均效应值$\bar{Z_{r}}$：

$$
\bar{Z_{r}}={{\sum_{i=1}^{k}(n_{i}-3)FisherZ_{i}}\over{\sum_{i=1}^{k}(n_{i}-3)}}
$$

其中，${1}\over{n_{i}-3}$是计算的权重值，同时也是不同的研究样本内方差(Within-Study Variance)。 

而在随机效应模型中，不仅需要考虑研究样本内方差，同时也要考虑研究样本间方差(Between-Study Variance ,用$\tau^{2}$表示 )，计算公式为： 

$$
\tau^{2}={{Q-(k-1)}\over{\sum_{i=1}^{k}(n_{i}-3)-{{\sum_{i=1}^{k}(n_{i}-3)^{2}}\over{\sum_{i=1}^{k}(n_{i}-3)}}}}
$$

随机效应模型中的权重值$w_{i}$等于： 

$$
w_{i}={{1}\over{{{1}\over{n_{i}-3}}+\tau^{2}}}
$$

所以，随机效应模型的加权平均效应值$\bar{Z_{r}}$为： 

$$
\bar{Z_{r}}={{\sum_{i=1}^{k}w_{i}FisherZ_{i}}\over{\sum_{i=1}^{k}w_{i}}}
$$

**4.2 相对权重分析**

相对权重分析(relative weight analysis)能够通过数据转换、相关分析和回归分析，计算各自变量对因变量的独立作用[@xuyan2019:RNG]。

在进行元分析时，可以通过以往的元分析和实证研究结果，形成研究变量间的相关矩阵。通过相关矩阵，可以计算出相对权重。[@Lebreton2008:RNG]提供了SPSS语法，利用输入的相关矩阵计算相对权重。

**5. 调节效应检验**

针对类别变量，通常采用分组比较分析(subgroup analysis)。分组比较在统计上通常来说具有更大的功效(power)。

针对连续型变量，主要采用加权回归分析(weighted regression analysis)。具体来说，把每个研究样本的效应值(或校正后的效应值)作为因变量，把潜在的调节变量作为自变量。与此同时，根据每个研究的样本量大小对每一个研究在回归分析中所占权重进行赋值。如果潜在调节变量对效应值的回归系数是显著的，那么就说明调节作用存在。如果有足够多的研究样本，建议采用加权回归分析方法。如果调节效应存在，可以进一步运用分组比较分析观察不同组的显著性。





































